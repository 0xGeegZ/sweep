{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "\n",
    "Language.build_library(f'/tmp/python.so', [f\"../tree-sitter-python\"]) \n",
    "language = Language(\"/tmp/python.so\", \"python\")\n",
    "parser = Parser()\n",
    "parser.set_language(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_example = '''\n",
    "from typing import Optional, cast\n",
    "from chromadb.api import API\n",
    "from chromadb.config import System\n",
    "from chromadb.api.types import (\n",
    "    Documents,\n",
    "    Embeddings,\n",
    "    EmbeddingFunction,\n",
    "    IDs,\n",
    "    Include,\n",
    "    Metadatas,\n",
    "    Where,\n",
    "    WhereDocument,\n",
    "    GetResult,\n",
    "    QueryResult,\n",
    "    CollectionMetadata,\n",
    ")\n",
    "import chromadb.utils.embedding_functions as ef\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from typing import Sequence\n",
    "from chromadb.api.models.Collection import Collection\n",
    "import chromadb.errors as errors\n",
    "from uuid import UUID\n",
    "\n",
    "\n",
    "class FastAPI(API):\n",
    "    def __init__(self, system: System):\n",
    "        url_prefix = \"https\" if system.settings.chroma_server_ssl_enabled else \"http\"\n",
    "        system.settings.require(\"chroma_server_host\")\n",
    "        system.settings.require(\"chroma_server_http_port\")\n",
    "        self._api_url = f\"{url_prefix}://{system.settings.chroma_server_host}:{system.settings.chroma_server_http_port}/api/v1\"\n",
    "        self._telemetry_client = system.get_telemetry()\n",
    "\n",
    "    def heartbeat(self) -> int:\n",
    "        \"\"\"Returns the current server time in nanoseconds to check if the server is alive\"\"\"\n",
    "        resp = requests.get(self._api_url)\n",
    "        raise_chroma_error(resp)\n",
    "        return int(resp.json()[\"nanosecond heartbeat\"])\n",
    "\n",
    "    def list_collections(self) -> Sequence[Collection]:\n",
    "        \"\"\"Returns a list of all collections\"\"\"\n",
    "        resp = requests.get(self._api_url + \"/collections\")\n",
    "        raise_chroma_error(resp)\n",
    "        json_collections = resp.json()\n",
    "        collections = []\n",
    "        for json_collection in json_collections:\n",
    "            collections.append(Collection(self, **json_collection))\n",
    "\n",
    "        return collections\n",
    "\n",
    "    def create_collection(\n",
    "        self,\n",
    "        name: str,\n",
    "        metadata: Optional[CollectionMetadata] = None,\n",
    "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
    "        get_or_create: bool = False,\n",
    "    ) -> Collection:\n",
    "        \"\"\"Creates a collection\"\"\"\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections\",\n",
    "            data=json.dumps(\n",
    "                {\"name\": name, \"metadata\": metadata, \"get_or_create\": get_or_create}\n",
    "            ),\n",
    "        )\n",
    "        raise_chroma_error(resp)\n",
    "        resp_json = resp.json()\n",
    "        return Collection(\n",
    "            client=self,\n",
    "            id=resp_json[\"id\"],\n",
    "            name=resp_json[\"name\"],\n",
    "            embedding_function=embedding_function,\n",
    "            metadata=resp_json[\"metadata\"],\n",
    "        )\n",
    "\n",
    "    def get_collection(\n",
    "        self,\n",
    "        name: str,\n",
    "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
    "    ) -> Collection:\n",
    "        \"\"\"Returns a collection\"\"\"\n",
    "        resp = requests.get(self._api_url + \"/collections/\" + name)\n",
    "        raise_chroma_error(resp)\n",
    "        resp_json = resp.json()\n",
    "        return Collection(\n",
    "            client=self,\n",
    "            name=resp_json[\"name\"],\n",
    "            id=resp_json[\"id\"],\n",
    "            embedding_function=embedding_function,\n",
    "            metadata=resp_json[\"metadata\"],\n",
    "        )\n",
    "\n",
    "    def get_or_create_collection(\n",
    "        self,\n",
    "        name: str,\n",
    "        metadata: Optional[CollectionMetadata] = None,\n",
    "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
    "    ) -> Collection:\n",
    "        \"\"\"Get a collection, or return it if it exists\"\"\"\n",
    "\n",
    "        return self.create_collection(\n",
    "            name, metadata, embedding_function, get_or_create=True\n",
    "        )\n",
    "\n",
    "    def _modify(\n",
    "        self,\n",
    "        id: UUID,\n",
    "        new_name: Optional[str] = None,\n",
    "        new_metadata: Optional[CollectionMetadata] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Updates a collection\"\"\"\n",
    "        resp = requests.put(\n",
    "            self._api_url + \"/collections/\" + str(id),\n",
    "            data=json.dumps({\"new_metadata\": new_metadata, \"new_name\": new_name}),\n",
    "        )\n",
    "        raise_chroma_error(resp)\n",
    "\n",
    "    def delete_collection(self, name: str) -> None:\n",
    "        \"\"\"Deletes a collection\"\"\"\n",
    "        resp = requests.delete(self._api_url + \"/collections/\" + name)\n",
    "        raise_chroma_error(resp)\n",
    "\n",
    "    def _count(self, collection_id: UUID) -> int:\n",
    "        \"\"\"Returns the number of embeddings in the database\"\"\"\n",
    "        resp = requests.get(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/count\"\n",
    "        )\n",
    "        raise_chroma_error(resp)\n",
    "        return cast(int, resp.json())\n",
    "\n",
    "    def _peek(self, collection_id: UUID, limit: int = 10) -> GetResult:\n",
    "        return self._get(\n",
    "            collection_id,\n",
    "            limit=limit,\n",
    "            include=[\"embeddings\", \"documents\", \"metadatas\"],\n",
    "        )\n",
    "\n",
    "    def _get(\n",
    "        self,\n",
    "        collection_id: UUID,\n",
    "        ids: Optional[IDs] = None,\n",
    "        where: Optional[Where] = {},\n",
    "        sort: Optional[str] = None,\n",
    "        limit: Optional[int] = None,\n",
    "        offset: Optional[int] = None,\n",
    "        page: Optional[int] = None,\n",
    "        page_size: Optional[int] = None,\n",
    "        where_document: Optional[WhereDocument] = {},\n",
    "        include: Include = [\"metadatas\", \"documents\"],\n",
    "    ) -> GetResult:\n",
    "        \"\"\"Gets embeddings from the database\"\"\"\n",
    "        if page and page_size:\n",
    "            offset = (page - 1) * page_size\n",
    "            limit = page_size\n",
    "\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/get\",\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"ids\": ids,\n",
    "                    \"where\": where,\n",
    "                    \"sort\": sort,\n",
    "                    \"limit\": limit,\n",
    "                    \"offset\": offset,\n",
    "                    \"where_document\": where_document,\n",
    "                    \"include\": include,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        raise_chroma_error(resp)\n",
    "        body = resp.json()\n",
    "        return GetResult(\n",
    "            ids=body[\"ids\"],\n",
    "            embeddings=body.get(\"embeddings\", None),\n",
    "            metadatas=body.get(\"metadatas\", None),\n",
    "            documents=body.get(\"documents\", None),\n",
    "        )\n",
    "\n",
    "    def _delete(\n",
    "        self,\n",
    "        collection_id: UUID,\n",
    "        ids: Optional[IDs] = None,\n",
    "        where: Optional[Where] = {},\n",
    "        where_document: Optional[WhereDocument] = {},\n",
    "    ) -> IDs:\n",
    "        \"\"\"Deletes embeddings from the database\"\"\"\n",
    "\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/delete\",\n",
    "            data=json.dumps(\n",
    "                {\"where\": where, \"ids\": ids, \"where_document\": where_document}\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        raise_chroma_error(resp)\n",
    "        return cast(IDs, resp.json())\n",
    "\n",
    "    def _add(\n",
    "        self,\n",
    "        ids: IDs,\n",
    "        collection_id: UUID,\n",
    "        embeddings: Embeddings,\n",
    "        metadatas: Optional[Metadatas] = None,\n",
    "        documents: Optional[Documents] = None,\n",
    "        increment_index: bool = True,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Adds a batch of embeddings to the database\n",
    "        - pass in column oriented data lists\n",
    "        - by default, the index is progressively built up as you add more data. If for ingestion performance reasons you want to disable this, set increment_index to False\n",
    "        -     and then manually create the index yourself with collection.create_index()\n",
    "        \"\"\"\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/add\",\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"ids\": ids,\n",
    "                    \"embeddings\": embeddings,\n",
    "                    \"metadatas\": metadatas,\n",
    "                    \"documents\": documents,\n",
    "                    \"increment_index\": increment_index,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        raise_chroma_error(resp)\n",
    "        return True\n",
    "\n",
    "    def _update(\n",
    "        self,\n",
    "        collection_id: UUID,\n",
    "        ids: IDs,\n",
    "        embeddings: Optional[Embeddings] = None,\n",
    "        metadatas: Optional[Metadatas] = None,\n",
    "        documents: Optional[Documents] = None,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Updates a batch of embeddings in the database\n",
    "        - pass in column oriented data lists\n",
    "        \"\"\"\n",
    "\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/update\",\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"ids\": ids,\n",
    "                    \"embeddings\": embeddings,\n",
    "                    \"metadatas\": metadatas,\n",
    "                    \"documents\": documents,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        resp.raise_for_status()\n",
    "        return True\n",
    "\n",
    "    def _upsert(\n",
    "        self,\n",
    "        collection_id: UUID,\n",
    "        ids: IDs,\n",
    "        embeddings: Embeddings,\n",
    "        metadatas: Optional[Metadatas] = None,\n",
    "        documents: Optional[Documents] = None,\n",
    "        increment_index: bool = True,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Updates a batch of embeddings in the database\n",
    "        - pass in column oriented data lists\n",
    "        \"\"\"\n",
    "\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/upsert\",\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"ids\": ids,\n",
    "                    \"embeddings\": embeddings,\n",
    "                    \"metadatas\": metadatas,\n",
    "                    \"documents\": documents,\n",
    "                    \"increment_index\": increment_index,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        resp.raise_for_status()\n",
    "        return True\n",
    "\n",
    "    def _query(\n",
    "        self,\n",
    "        collection_id: UUID,\n",
    "        query_embeddings: Embeddings,\n",
    "        n_results: int = 10,\n",
    "        where: Optional[Where] = {},\n",
    "        where_document: Optional[WhereDocument] = {},\n",
    "        include: Include = [\"metadatas\", \"documents\", \"distances\"],\n",
    "    ) -> QueryResult:\n",
    "        \"\"\"Gets the nearest neighbors of a single embedding\"\"\"\n",
    "\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + str(collection_id) + \"/query\",\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"query_embeddings\": query_embeddings,\n",
    "                    \"n_results\": n_results,\n",
    "                    \"where\": where,\n",
    "                    \"where_document\": where_document,\n",
    "                    \"include\": include,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        raise_chroma_error(resp)\n",
    "        body = resp.json()\n",
    "\n",
    "        return QueryResult(\n",
    "            ids=body[\"ids\"],\n",
    "            distances=body.get(\"distances\", None),\n",
    "            embeddings=body.get(\"embeddings\", None),\n",
    "            metadatas=body.get(\"metadatas\", None),\n",
    "            documents=body.get(\"documents\", None),\n",
    "        )\n",
    "\n",
    "    def reset(self) -> bool:\n",
    "        \"\"\"Resets the database\"\"\"\n",
    "        resp = requests.post(self._api_url + \"/reset\")\n",
    "        raise_chroma_error(resp)\n",
    "        return cast(bool, resp.json())\n",
    "\n",
    "    def persist(self) -> bool:\n",
    "        \"\"\"Persists the database\"\"\"\n",
    "        resp = requests.post(self._api_url + \"/persist\")\n",
    "        raise_chroma_error(resp)\n",
    "        return cast(bool, resp.json())\n",
    "\n",
    "    def raw_sql(self, sql: str) -> pd.DataFrame:\n",
    "        \"\"\"Runs a raw SQL query against the database\"\"\"\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/raw_sql\", data=json.dumps({\"raw_sql\": sql})\n",
    "        )\n",
    "        raise_chroma_error(resp)\n",
    "        return pd.DataFrame.from_dict(resp.json())\n",
    "\n",
    "    def create_index(self, collection_name: str) -> bool:\n",
    "        \"\"\"Creates an index for the given space key\"\"\"\n",
    "        resp = requests.post(\n",
    "            self._api_url + \"/collections/\" + collection_name + \"/create_index\"\n",
    "        )\n",
    "        raise_chroma_error(resp)\n",
    "        return cast(bool, resp.json())\n",
    "\n",
    "    def get_version(self) -> str:\n",
    "        \"\"\"Returns the version of the server\"\"\"\n",
    "        resp = requests.get(self._api_url + \"/version\")\n",
    "        raise_chroma_error(resp)\n",
    "        return cast(str, resp.json())\n",
    "\n",
    "\n",
    "def raise_chroma_error(resp: requests.Response) -> None:\n",
    "    \"\"\"Raises an error if the response is not ok, using a ChromaError if possible\"\"\"\n",
    "    if resp.ok:\n",
    "        return\n",
    "\n",
    "    chroma_error = None\n",
    "    try:\n",
    "        body = resp.json()\n",
    "        if \"error\" in body:\n",
    "            if body[\"error\"] in errors.error_types:\n",
    "                chroma_error = errors.error_types[body[\"error\"]](body[\"message\"])\n",
    "\n",
    "    except BaseException:\n",
    "        pass\n",
    "\n",
    "    if chroma_error:\n",
    "        raise chroma_error\n",
    "\n",
    "    try:\n",
    "        resp.raise_for_status()\n",
    "    except requests.HTTPError:\n",
    "        raise (Exception(resp.text))\n",
    "'''\n",
    "\n",
    "tree = parser.parse(bytes(python_example, \"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: module, Slice: 1:12142, Content: from typing import O\n",
      "  Type: import_from_statement, Slice: 1:34, Content: from typing import O\n",
      "  Type: import_from_statement, Slice: 35:63, Content: from chromadb.api im\n",
      "  Type: import_from_statement, Slice: 64:98, Content: from chromadb.config\n",
      "  Type: import_from_statement, Slice: 99:310, Content: from chromadb.api.ty\n",
      "  Type: import_statement, Slice: 311:358, Content: import chromadb.util\n",
      "  Type: import_statement, Slice: 359:378, Content: import pandas as pd\n",
      "  Type: import_statement, Slice: 379:394, Content: import requests\n",
      "  Type: import_statement, Slice: 395:406, Content: import json\n",
      "  Type: import_from_statement, Slice: 407:434, Content: from typing import S\n",
      "  Type: import_from_statement, Slice: 435:488, Content: from chromadb.api.mo\n",
      "  Type: import_statement, Slice: 489:521, Content: import chromadb.erro\n",
      "  Type: import_from_statement, Slice: 522:543, Content: from uuid import UUI\n",
      "  Type: class_definition, Slice: 546:11544, Content: class FastAPI(API):\n",
      "\n",
      "    Type: class, Slice: 546:551, Content: class\n",
      "    Type: identifier, Slice: 552:559, Content: FastAPI\n",
      "    Type: argument_list, Slice: 559:564, Content: (API)\n",
      "    Type: :, Slice: 564:565, Content: :\n",
      "    Type: block, Slice: 570:11544, Content: def __init__(self, s\n",
      "      Type: function_definition, Slice: 570:988, Content: def __init__(self, s\n",
      "      Type: function_definition, Slice: 994:1246, Content: def heartbeat(self) \n",
      "      Type: function_definition, Slice: 1252:1653, Content: def list_collections\n",
      "      Type: function_definition, Slice: 1659:2454, Content: def create_collectio\n",
      "      Type: function_definition, Slice: 2460:3015, Content: def get_collection(\n",
      "\n",
      "      Type: function_definition, Slice: 3021:3423, Content: def get_or_create_co\n",
      "      Type: function_definition, Slice: 3429:3832, Content: def _modify(\n",
      "       \n",
      "      Type: function_definition, Slice: 3838:4024, Content: def delete_collectio\n",
      "      Type: function_definition, Slice: 4030:4324, Content: def _count(self, col\n",
      "      Type: function_definition, Slice: 4330:4547, Content: def _peek(self, coll\n",
      "      Type: function_definition, Slice: 4553:5894, Content: def _get(\n",
      "        se\n",
      "        Type: def, Slice: 4553:4556, Content: def\n",
      "        Type: identifier, Slice: 4557:4561, Content: _get\n",
      "        Type: parameters, Slice: 4561:4980, Content: (\n",
      "        self,\n",
      "    \n",
      "        Type: ->, Slice: 4981:4983, Content: ->\n",
      "        Type: type, Slice: 4984:4993, Content: GetResult\n",
      "        Type: :, Slice: 4993:4994, Content: :\n",
      "        Type: block, Slice: 5003:5894, Content: \"\"\"Gets embeddings f\n",
      "      Type: function_definition, Slice: 5900:6460, Content: def _delete(\n",
      "       \n",
      "      Type: function_definition, Slice: 6466:7567, Content: def _add(\n",
      "        se\n",
      "        Type: def, Slice: 6466:6469, Content: def\n",
      "        Type: identifier, Slice: 6470:6474, Content: _add\n",
      "        Type: parameters, Slice: 6474:6706, Content: (\n",
      "        self,\n",
      "    \n",
      "        Type: ->, Slice: 6707:6709, Content: ->\n",
      "        Type: type, Slice: 6710:6714, Content: bool\n",
      "        Type: :, Slice: 6714:6715, Content: :\n",
      "        Type: block, Slice: 6724:7567, Content: \"\"\"\n",
      "        Adds a b\n",
      "      Type: function_definition, Slice: 7573:8345, Content: def _update(\n",
      "       \n",
      "      Type: function_definition, Slice: 8351:9200, Content: def _upsert(\n",
      "       \n",
      "      Type: function_definition, Slice: 9206:10336, Content: def _query(\n",
      "        \n",
      "        Type: def, Slice: 9206:9209, Content: def\n",
      "        Type: identifier, Slice: 9210:9216, Content: _query\n",
      "        Type: parameters, Slice: 9216:9492, Content: (\n",
      "        self,\n",
      "    \n",
      "        Type: ->, Slice: 9493:9495, Content: ->\n",
      "        Type: type, Slice: 9496:9507, Content: QueryResult\n",
      "        Type: :, Slice: 9507:9508, Content: :\n",
      "        Type: block, Slice: 9517:10336, Content: \"\"\"Gets the nearest \n",
      "      Type: function_definition, Slice: 10342:10527, Content: def reset(self) -> b\n",
      "      Type: function_definition, Slice: 10533:10724, Content: def persist(self) ->\n",
      "      Type: function_definition, Slice: 10730:11028, Content: def raw_sql(self, sq\n",
      "      Type: function_definition, Slice: 11034:11334, Content: def create_index(sel\n",
      "      Type: function_definition, Slice: 11340:11544, Content: def get_version(self\n",
      "  Type: function_definition, Slice: 11547:12141, Content: def raise_chroma_err\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pretty print tree recursively\n",
    "from tree_sitter import Node\n",
    "\n",
    "threshold = 1000\n",
    "def pretty_print_tree(node: Node, source_code, indent=0):\n",
    "    result = ''\n",
    "    result += ' ' * indent + f'Type: {node.type}, Slice: {node.start_byte}:{node.end_byte}, Content: {source_code[node.start_byte:min(node.end_byte, node.start_byte + 20)]}\\n'\n",
    "\n",
    "    if node.end_byte - node.start_byte > threshold:\n",
    "        for child in node.children:\n",
    "            result += pretty_print_tree(child, source_code, indent + 2)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(pretty_print_tree(tree.root_node, python_example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    start: int\n",
    "    end: int\n",
    "\n",
    "    def extract(self, s: str) -> str:\n",
    "        # return s[self.start:self.end]\n",
    "        return \"\\n\".join(s.splitlines()[self.start:self.end])\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, int):\n",
    "            return Chunk(self.start + other, self.end + other)\n",
    "        elif isinstance(other, Chunk):\n",
    "            return Chunk(self.start, other.end)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_chunker(source_code: str, chunk_lines: int = 20, start_position: int = 0) -> list[Chunk]:\n",
    "    source_lines = source_code.split('\\n')\n",
    "    num_lines = len(source_lines)\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    start_line = 0\n",
    "    while start_line < num_lines:\n",
    "        end_line = min(start_line + chunk_lines, num_lines)\n",
    "        chunk_string = '\\n'.join(source_code[start_line:end_line]) + \"\\n\"\n",
    "        if len(chunk_string) > 2:\n",
    "            chunks.append(Chunk(start + start_position, start + len(chunk_string) + start_position))\n",
    "            start += len(chunk_string)\n",
    "        start_line += chunk_lines\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import Optional, cast\n",
      "\n",
      "\n",
      "from chromadb.api import API\n",
      "\n",
      "\n",
      "from chromadb.config import System\n",
      "\n",
      "\n",
      "from chromadb.api.types import (\n",
      "    Documents,\n",
      "    Embeddings,\n",
      "    EmbeddingFunction,\n",
      "    IDs,\n",
      "    Include,\n",
      "    Metadatas,\n",
      "    Where,\n",
      "    WhereDocument,\n",
      "    GetResult,\n",
      "    QueryResult,\n",
      "    CollectionMetadata,\n",
      ")\n",
      "\n",
      "\n",
      "import chromadb.utils.embedding_functions as ef\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "import requests\n",
      "\n",
      "\n",
      "import json\n",
      "\n",
      "\n",
      "from typing import Sequence\n",
      "\n",
      "\n",
      "from chromadb.api.models.Collection import Collection\n",
      "\n",
      "\n",
      "import chromadb.errors as errors\n",
      "\n",
      "\n",
      "from uuid import UUID\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class FastAPI(API):\n",
      "\n",
      "\n",
      "    def __init__(self, system: System):\n",
      "        url_prefix = \"https\" if system.settings.chroma_server_ssl_enabled else \"http\"\n",
      "        system.settings.require(\"chroma_server_host\")\n",
      "        system.settings.require(\"chroma_server_http_port\")\n",
      "        self._api_url = f\"{url_prefix}://{system.settings.chroma_server_host}:{system.settings.chroma_server_http_port}/api/v1\"\n",
      "        self._telemetry_client = system.get_telemetry()\n",
      "\n",
      "\n",
      "\n",
      "    def heartbeat(self) -> int:\n",
      "        \"\"\"Returns the current server time in nanoseconds to check if the server is alive\"\"\"\n",
      "        resp = requests.get(self._api_url)\n",
      "        raise_chroma_error(resp)\n",
      "        return int(resp.json()[\"nanosecond heartbeat\"])\n",
      "\n",
      "\n",
      "\n",
      "    def list_collections(self) -> Sequence[Collection]:\n",
      "        \"\"\"Returns a list of all collections\"\"\"\n",
      "        resp = requests.get(self._api_url + \"/collections\")\n",
      "        raise_chroma_error(resp)\n",
      "        json_collections = resp.json()\n",
      "        collections = []\n",
      "        for json_collection in json_collections:\n",
      "            collections.append(Collection(self, **json_collection))\n",
      "\n",
      "        return collections\n",
      "\n",
      "\n",
      "\n",
      "    def create_collection(\n",
      "        self,\n",
      "        name: str,\n",
      "        metadata: Optional[CollectionMetadata] = None,\n",
      "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
      "        get_or_create: bool = False,\n",
      "    ) -> Collection:\n",
      "        \"\"\"Creates a collection\"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections\",\n",
      "            data=json.dumps(\n",
      "                {\"name\": name, \"metadata\": metadata, \"get_or_create\": get_or_create}\n",
      "            ),\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        resp_json = resp.json()\n",
      "        return Collection(\n",
      "            client=self,\n",
      "            id=resp_json[\"id\"],\n",
      "            name=resp_json[\"name\"],\n",
      "            embedding_function=embedding_function,\n",
      "            metadata=resp_json[\"metadata\"],\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    def get_collection(\n",
      "        self,\n",
      "        name: str,\n",
      "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
      "    ) -> Collection:\n",
      "        \"\"\"Returns a collection\"\"\"\n",
      "        resp = requests.get(self._api_url + \"/collections/\" + name)\n",
      "        raise_chroma_error(resp)\n",
      "        resp_json = resp.json()\n",
      "        return Collection(\n",
      "            client=self,\n",
      "            name=resp_json[\"name\"],\n",
      "            id=resp_json[\"id\"],\n",
      "            embedding_function=embedding_function,\n",
      "            metadata=resp_json[\"metadata\"],\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    def get_or_create_collection(\n",
      "        self,\n",
      "        name: str,\n",
      "        metadata: Optional[CollectionMetadata] = None,\n",
      "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
      "    ) -> Collection:\n",
      "        \"\"\"Get a collection, or return it if it exists\"\"\"\n",
      "\n",
      "        return self.create_collection(\n",
      "            name, metadata, embedding_function, get_or_create=True\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    def _modify(\n",
      "        self,\n",
      "        id: UUID,\n",
      "        new_name: Optional[str] = None,\n",
      "        new_metadata: Optional[CollectionMetadata] = None,\n",
      "    ) -> None:\n",
      "        \"\"\"Updates a collection\"\"\"\n",
      "        resp = requests.put(\n",
      "            self._api_url + \"/collections/\" + str(id),\n",
      "            data=json.dumps({\"new_metadata\": new_metadata, \"new_name\": new_name}),\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "\n",
      "\n",
      "\n",
      "    def delete_collection(self, name: str) -> None:\n",
      "        \"\"\"Deletes a collection\"\"\"\n",
      "        resp = requests.delete(self._api_url + \"/collections/\" + name)\n",
      "        raise_chroma_error(resp)\n",
      "\n",
      "\n",
      "\n",
      "    def _count(self, collection_id: UUID) -> int:\n",
      "        \"\"\"Returns the number of embeddings in the database\"\"\"\n",
      "        resp = requests.get(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/count\"\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(int, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "    def _peek(self, collection_id: UUID, limit: int = 10) -> GetResult:\n",
      "        return self._get(\n",
      "            collection_id,\n",
      "            limit=limit,\n",
      "            include=[\"embeddings\", \"documents\", \"metadatas\"],\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    def _get(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: Optional[IDs] = None,\n",
      "        where: Optional[Where] = {},\n",
      "        sort: Optional[str] = None,\n",
      "        limit: Optional[int] = None,\n",
      "        offset: Optional[int] = None,\n",
      "        page: Optional[int] = None,\n",
      "        page_size: Optional[int] = None,\n",
      "        where_document: Optional[WhereDocument] = {},\n",
      "        include: Include = [\"metadatas\", \"documents\"],\n",
      "    ) -> GetResult:\n",
      "        \"\"\"Gets embeddings from the database\"\"\"\n",
      "        if page and page_size:\n",
      "            offset = (page - 1) * page_size\n",
      "            limit = page_size\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/get\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"where\": where,\n",
      "                    \"sort\": sort,\n",
      "                    \"limit\": limit,\n",
      "                    \"offset\": offset,\n",
      "                    \"where_document\": where_document,\n",
      "                    \"include\": include,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        body = resp.json()\n",
      "        return GetResult(\n",
      "            ids=body[\"ids\"],\n",
      "            embeddings=body.get(\"embeddings\", None),\n",
      "            metadatas=body.get(\"metadatas\", None),\n",
      "            documents=body.get(\"documents\", None),\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    def _delete(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: Optional[IDs] = None,\n",
      "        where: Optional[Where] = {},\n",
      "        where_document: Optional[WhereDocument] = {},\n",
      "    ) -> IDs:\n",
      "        \"\"\"Deletes embeddings from the database\"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/delete\",\n",
      "            data=json.dumps(\n",
      "                {\"where\": where, \"ids\": ids, \"where_document\": where_document}\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(IDs, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "    def _add(\n",
      "        self,\n",
      "        ids: IDs,\n",
      "        collection_id: UUID,\n",
      "        embeddings: Embeddings,\n",
      "        metadatas: Optional[Metadatas] = None,\n",
      "        documents: Optional[Documents] = None,\n",
      "        increment_index: bool = True,\n",
      "    ) -> bool:\n",
      "        \"\"\"\n",
      "        Adds a batch of embeddings to the database\n",
      "        - pass in column oriented data lists\n",
      "        - by default, the index is progressively built up as you add more data. If for ingestion performance reasons you want to disable this, set increment_index to False\n",
      "        -     and then manually create the index yourself with collection.create_index()\n",
      "        \"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/add\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"embeddings\": embeddings,\n",
      "                    \"metadatas\": metadatas,\n",
      "                    \"documents\": documents,\n",
      "                    \"increment_index\": increment_index,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "    def _update(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: IDs,\n",
      "        embeddings: Optional[Embeddings] = None,\n",
      "        metadatas: Optional[Metadatas] = None,\n",
      "        documents: Optional[Documents] = None,\n",
      "    ) -> bool:\n",
      "        \"\"\"\n",
      "        Updates a batch of embeddings in the database\n",
      "        - pass in column oriented data lists\n",
      "        \"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/update\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"embeddings\": embeddings,\n",
      "                    \"metadatas\": metadatas,\n",
      "                    \"documents\": documents,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        resp.raise_for_status()\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "    def _upsert(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: IDs,\n",
      "        embeddings: Embeddings,\n",
      "        metadatas: Optional[Metadatas] = None,\n",
      "        documents: Optional[Documents] = None,\n",
      "        increment_index: bool = True,\n",
      "    ) -> bool:\n",
      "        \"\"\"\n",
      "        Updates a batch of embeddings in the database\n",
      "        - pass in column oriented data lists\n",
      "        \"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/upsert\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"embeddings\": embeddings,\n",
      "                    \"metadatas\": metadatas,\n",
      "                    \"documents\": documents,\n",
      "                    \"increment_index\": increment_index,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        resp.raise_for_status()\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "    def _query(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        query_embeddings: Embeddings,\n",
      "        n_results: int = 10,\n",
      "        where: Optional[Where] = {},\n",
      "        where_document: Optional[WhereDocument] = {},\n",
      "        include: Include = [\"metadatas\", \"documents\", \"distances\"],\n",
      "    ) -> QueryResult:\n",
      "        \"\"\"Gets the nearest neighbors of a single embedding\"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/query\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"query_embeddings\": query_embeddings,\n",
      "                    \"n_results\": n_results,\n",
      "                    \"where\": where,\n",
      "                    \"where_document\": where_document,\n",
      "                    \"include\": include,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        body = resp.json()\n",
      "\n",
      "        return QueryResult(\n",
      "            ids=body[\"ids\"],\n",
      "            distances=body.get(\"distances\", None),\n",
      "            embeddings=body.get(\"embeddings\", None),\n",
      "            metadatas=body.get(\"metadatas\", None),\n",
      "            documents=body.get(\"documents\", None),\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    def reset(self) -> bool:\n",
      "        \"\"\"Resets the database\"\"\"\n",
      "        resp = requests.post(self._api_url + \"/reset\")\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(bool, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "    def persist(self) -> bool:\n",
      "        \"\"\"Persists the database\"\"\"\n",
      "        resp = requests.post(self._api_url + \"/persist\")\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(bool, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "    def raw_sql(self, sql: str) -> pd.DataFrame:\n",
      "        \"\"\"Runs a raw SQL query against the database\"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/raw_sql\", data=json.dumps({\"raw_sql\": sql})\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        return pd.DataFrame.from_dict(resp.json())\n",
      "\n",
      "\n",
      "\n",
      "    def create_index(self, collection_name: str) -> bool:\n",
      "        \"\"\"Creates an index for the given space key\"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + collection_name + \"/create_index\"\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(bool, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "    def get_version(self) -> str:\n",
      "        \"\"\"Returns the version of the server\"\"\"\n",
      "        resp = requests.get(self._api_url + \"/version\")\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(str, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def raise_chroma_error(resp: requests.Response) -> None:\n",
      "    \"\"\"Raises an error if the response is not ok, using a ChromaError if possible\"\"\"\n",
      "    if resp.ok:\n",
      "        return\n",
      "\n",
      "    chroma_error = None\n",
      "    try:\n",
      "        body = resp.json()\n",
      "        if \"error\" in body:\n",
      "            if body[\"error\"] in errors.error_types:\n",
      "                chroma_error = errors.error_types[body[\"error\"]](body[\"message\"])\n",
      "\n",
      "    except BaseException:\n",
      "        pass\n",
      "\n",
      "    if chroma_error:\n",
      "        raise chroma_error\n",
      "\n",
      "    try:\n",
      "        resp.raise_for_status()\n",
      "    except requests.HTTPError:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def flatten(node: Node, source_code, max_chunk_size=1500) -> list[tuple[int, int]]:\n",
    "    if node.end_byte - node.start_byte > max_chunk_size:\n",
    "        result = []\n",
    "        for child in node.children:\n",
    "            result += flatten(child, source_code)\n",
    "        for prev, curr in zip(result[:-1], result[1:]): # ensures there are no gaps\n",
    "            prev[1] = curr[0]\n",
    "        return result\n",
    "    else:\n",
    "        return [[node.start_byte, node.end_byte]]\n",
    "\n",
    "def char_number_to_line_number(index: int, source_code: str) -> int:\n",
    "    lines = source_code.splitlines(keepends=True)\n",
    "    total_chars = 0\n",
    "    line_number = 0\n",
    "    while total_chars <= index:\n",
    "        total_chars += len(lines[line_number])\n",
    "        line_number += 1\n",
    "    return line_number - 1\n",
    "\n",
    "flattened = flatten(tree.root_node, python_example)\n",
    "flattened_line_numbers = [Chunk(char_number_to_line_number(start, python_example), char_number_to_line_number(end, python_example)) for start, end in flattened]\n",
    "for chunk in flattened_line_numbers:\n",
    "    print(chunk.extract(python_example) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from typing import Optional, cast\n",
      "from chromadb.api import API\n",
      "from chromadb.config import System\n",
      "from chromadb.api.types import (\n",
      "    Documents,\n",
      "    Embeddings,\n",
      "    EmbeddingFunction,\n",
      "    IDs,\n",
      "    Include,\n",
      "    Metadatas,\n",
      "    Where,\n",
      "    WhereDocument,\n",
      "    GetResult,\n",
      "    QueryResult,\n",
      "    CollectionMetadata,\n",
      ")\n",
      "import chromadb.utils.embedding_functions as ef\n",
      "import pandas as pd\n",
      "import requests\n",
      "import json\n",
      "from typing import Sequence\n",
      "from chromadb.api.models.Collection import Collection\n",
      "import chromadb.errors as errors\n",
      "from uuid import UUID\n",
      "\n",
      "\n",
      "class FastAPI(API):\n",
      "    def __init__(self, system: System):\n",
      "        url_prefix = \"https\" if system.settings.chroma_server_ssl_enabled else \"http\"\n",
      "        system.settings.require(\"chroma_server_host\")\n",
      "        system.settings.require(\"chroma_server_http_port\")\n",
      "        self._api_url = f\"{url_prefix}://{system.settings.chroma_server_host}:{system.settings.chroma_server_http_port}/api/v1\"\n",
      "        self._telemetry_client = system.get_telemetry()\n",
      "\n",
      "    def heartbeat(self) -> int:\n",
      "        \"\"\"Returns the current server time in nanoseconds to check if the server is alive\"\"\"\n",
      "        resp = requests.get(self._api_url)\n",
      "        raise_chroma_error(resp)\n",
      "        return int(resp.json()[\"nanosecond heartbeat\"])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def list_collections(self) -> Sequence[Collection]:\n",
      "        \"\"\"Returns a list of all collections\"\"\"\n",
      "        resp = requests.get(self._api_url + \"/collections\")\n",
      "        raise_chroma_error(resp)\n",
      "        json_collections = resp.json()\n",
      "        collections = []\n",
      "        for json_collection in json_collections:\n",
      "            collections.append(Collection(self, **json_collection))\n",
      "\n",
      "        return collections\n",
      "\n",
      "    def create_collection(\n",
      "        self,\n",
      "        name: str,\n",
      "        metadata: Optional[CollectionMetadata] = None,\n",
      "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
      "        get_or_create: bool = False,\n",
      "    ) -> Collection:\n",
      "        \"\"\"Creates a collection\"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections\",\n",
      "            data=json.dumps(\n",
      "                {\"name\": name, \"metadata\": metadata, \"get_or_create\": get_or_create}\n",
      "            ),\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        resp_json = resp.json()\n",
      "        return Collection(\n",
      "            client=self,\n",
      "            id=resp_json[\"id\"],\n",
      "            name=resp_json[\"name\"],\n",
      "            embedding_function=embedding_function,\n",
      "            metadata=resp_json[\"metadata\"],\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def get_collection(\n",
      "        self,\n",
      "        name: str,\n",
      "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
      "    ) -> Collection:\n",
      "        \"\"\"Returns a collection\"\"\"\n",
      "        resp = requests.get(self._api_url + \"/collections/\" + name)\n",
      "        raise_chroma_error(resp)\n",
      "        resp_json = resp.json()\n",
      "        return Collection(\n",
      "            client=self,\n",
      "            name=resp_json[\"name\"],\n",
      "            id=resp_json[\"id\"],\n",
      "            embedding_function=embedding_function,\n",
      "            metadata=resp_json[\"metadata\"],\n",
      "        )\n",
      "\n",
      "    def get_or_create_collection(\n",
      "        self,\n",
      "        name: str,\n",
      "        metadata: Optional[CollectionMetadata] = None,\n",
      "        embedding_function: Optional[EmbeddingFunction] = ef.DefaultEmbeddingFunction(),\n",
      "    ) -> Collection:\n",
      "        \"\"\"Get a collection, or return it if it exists\"\"\"\n",
      "\n",
      "        return self.create_collection(\n",
      "            name, metadata, embedding_function, get_or_create=True\n",
      "        )\n",
      "\n",
      "    def _modify(\n",
      "        self,\n",
      "        id: UUID,\n",
      "        new_name: Optional[str] = None,\n",
      "        new_metadata: Optional[CollectionMetadata] = None,\n",
      "    ) -> None:\n",
      "        \"\"\"Updates a collection\"\"\"\n",
      "        resp = requests.put(\n",
      "            self._api_url + \"/collections/\" + str(id),\n",
      "            data=json.dumps({\"new_metadata\": new_metadata, \"new_name\": new_name}),\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def delete_collection(self, name: str) -> None:\n",
      "        \"\"\"Deletes a collection\"\"\"\n",
      "        resp = requests.delete(self._api_url + \"/collections/\" + name)\n",
      "        raise_chroma_error(resp)\n",
      "\n",
      "    def _count(self, collection_id: UUID) -> int:\n",
      "        \"\"\"Returns the number of embeddings in the database\"\"\"\n",
      "        resp = requests.get(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/count\"\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(int, resp.json())\n",
      "\n",
      "    def _peek(self, collection_id: UUID, limit: int = 10) -> GetResult:\n",
      "        return self._get(\n",
      "            collection_id,\n",
      "            limit=limit,\n",
      "            include=[\"embeddings\", \"documents\", \"metadatas\"],\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def _get(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: Optional[IDs] = None,\n",
      "        where: Optional[Where] = {},\n",
      "        sort: Optional[str] = None,\n",
      "        limit: Optional[int] = None,\n",
      "        offset: Optional[int] = None,\n",
      "        page: Optional[int] = None,\n",
      "        page_size: Optional[int] = None,\n",
      "        where_document: Optional[WhereDocument] = {},\n",
      "        include: Include = [\"metadatas\", \"documents\"],\n",
      "    ) -> GetResult:\n",
      "        \"\"\"Gets embeddings from the database\"\"\"\n",
      "        if page and page_size:\n",
      "            offset = (page - 1) * page_size\n",
      "            limit = page_size\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/get\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"where\": where,\n",
      "                    \"sort\": sort,\n",
      "                    \"limit\": limit,\n",
      "                    \"offset\": offset,\n",
      "                    \"where_document\": where_document,\n",
      "                    \"include\": include,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        body = resp.json()\n",
      "        return GetResult(\n",
      "            ids=body[\"ids\"],\n",
      "            embeddings=body.get(\"embeddings\", None),\n",
      "            metadatas=body.get(\"metadatas\", None),\n",
      "            documents=body.get(\"documents\", None),\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def _delete(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: Optional[IDs] = None,\n",
      "        where: Optional[Where] = {},\n",
      "        where_document: Optional[WhereDocument] = {},\n",
      "    ) -> IDs:\n",
      "        \"\"\"Deletes embeddings from the database\"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/delete\",\n",
      "            data=json.dumps(\n",
      "                {\"where\": where, \"ids\": ids, \"where_document\": where_document}\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(IDs, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def _add(\n",
      "        self,\n",
      "        ids: IDs,\n",
      "        collection_id: UUID,\n",
      "        embeddings: Embeddings,\n",
      "        metadatas: Optional[Metadatas] = None,\n",
      "        documents: Optional[Documents] = None,\n",
      "        increment_index: bool = True,\n",
      "    ) -> bool:\n",
      "        \"\"\"\n",
      "        Adds a batch of embeddings to the database\n",
      "        - pass in column oriented data lists\n",
      "        - by default, the index is progressively built up as you add more data. If for ingestion performance reasons you want to disable this, set increment_index to False\n",
      "        -     and then manually create the index yourself with collection.create_index()\n",
      "        \"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/add\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"embeddings\": embeddings,\n",
      "                    \"metadatas\": metadatas,\n",
      "                    \"documents\": documents,\n",
      "                    \"increment_index\": increment_index,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def _update(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: IDs,\n",
      "        embeddings: Optional[Embeddings] = None,\n",
      "        metadatas: Optional[Metadatas] = None,\n",
      "        documents: Optional[Documents] = None,\n",
      "    ) -> bool:\n",
      "        \"\"\"\n",
      "        Updates a batch of embeddings in the database\n",
      "        - pass in column oriented data lists\n",
      "        \"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/update\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"embeddings\": embeddings,\n",
      "                    \"metadatas\": metadatas,\n",
      "                    \"documents\": documents,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        resp.raise_for_status()\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def _upsert(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        ids: IDs,\n",
      "        embeddings: Embeddings,\n",
      "        metadatas: Optional[Metadatas] = None,\n",
      "        documents: Optional[Documents] = None,\n",
      "        increment_index: bool = True,\n",
      "    ) -> bool:\n",
      "        \"\"\"\n",
      "        Updates a batch of embeddings in the database\n",
      "        - pass in column oriented data lists\n",
      "        \"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/upsert\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"ids\": ids,\n",
      "                    \"embeddings\": embeddings,\n",
      "                    \"metadatas\": metadatas,\n",
      "                    \"documents\": documents,\n",
      "                    \"increment_index\": increment_index,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        resp.raise_for_status()\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def _query(\n",
      "        self,\n",
      "        collection_id: UUID,\n",
      "        query_embeddings: Embeddings,\n",
      "        n_results: int = 10,\n",
      "        where: Optional[Where] = {},\n",
      "        where_document: Optional[WhereDocument] = {},\n",
      "        include: Include = [\"metadatas\", \"documents\", \"distances\"],\n",
      "    ) -> QueryResult:\n",
      "        \"\"\"Gets the nearest neighbors of a single embedding\"\"\"\n",
      "\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + str(collection_id) + \"/query\",\n",
      "            data=json.dumps(\n",
      "                {\n",
      "                    \"query_embeddings\": query_embeddings,\n",
      "                    \"n_results\": n_results,\n",
      "                    \"where\": where,\n",
      "                    \"where_document\": where_document,\n",
      "                    \"include\": include,\n",
      "                }\n",
      "            ),\n",
      "        )\n",
      "\n",
      "        raise_chroma_error(resp)\n",
      "        body = resp.json()\n",
      "\n",
      "        return QueryResult(\n",
      "            ids=body[\"ids\"],\n",
      "            distances=body.get(\"distances\", None),\n",
      "            embeddings=body.get(\"embeddings\", None),\n",
      "            metadatas=body.get(\"metadatas\", None),\n",
      "            documents=body.get(\"documents\", None),\n",
      "        )\n",
      "\n",
      "    def reset(self) -> bool:\n",
      "        \"\"\"Resets the database\"\"\"\n",
      "        resp = requests.post(self._api_url + \"/reset\")\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(bool, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def persist(self) -> bool:\n",
      "        \"\"\"Persists the database\"\"\"\n",
      "        resp = requests.post(self._api_url + \"/persist\")\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(bool, resp.json())\n",
      "\n",
      "    def raw_sql(self, sql: str) -> pd.DataFrame:\n",
      "        \"\"\"Runs a raw SQL query against the database\"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/raw_sql\", data=json.dumps({\"raw_sql\": sql})\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        return pd.DataFrame.from_dict(resp.json())\n",
      "\n",
      "    def create_index(self, collection_name: str) -> bool:\n",
      "        \"\"\"Creates an index for the given space key\"\"\"\n",
      "        resp = requests.post(\n",
      "            self._api_url + \"/collections/\" + collection_name + \"/create_index\"\n",
      "        )\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(bool, resp.json())\n",
      "\n",
      "    def get_version(self) -> str:\n",
      "        \"\"\"Returns the version of the server\"\"\"\n",
      "        resp = requests.get(self._api_url + \"/version\")\n",
      "        raise_chroma_error(resp)\n",
      "        return cast(str, resp.json())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def raise_chroma_error(resp: requests.Response) -> None:\n",
      "    \"\"\"Raises an error if the response is not ok, using a ChromaError if possible\"\"\"\n",
      "    if resp.ok:\n",
      "        return\n",
      "\n",
      "    chroma_error = None\n",
      "    try:\n",
      "        body = resp.json()\n",
      "        if \"error\" in body:\n",
      "            if body[\"error\"] in errors.error_types:\n",
      "                chroma_error = errors.error_types[body[\"error\"]](body[\"message\"])\n",
      "\n",
      "    except BaseException:\n",
      "        pass\n",
      "\n",
      "    if chroma_error:\n",
      "        raise chroma_error\n",
      "\n",
      "    try:\n",
      "        resp.raise_for_status()\n",
      "    except requests.HTTPError:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chunker(source_code: str, max_chunk_size=1500) -> list[Chunk]:\n",
    "    tree = parser.parse(bytes(source_code, \"utf-8\"))\n",
    "    flattened = [Chunk(char_number_to_line_number(start, source_code), char_number_to_line_number(end, source_code)) for start, end in flatten(tree.root_node, source_code)]\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = Chunk(0, 0)\n",
    "    lines = source_code.splitlines(keepends=True)\n",
    "    for chunk in flattened:\n",
    "        if sum([len(line) for line in lines[current_chunk.start:current_chunk.end]])\\\n",
    "            + sum([len(line) for line in lines[chunk.start:chunk.end]]) > max_chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = chunk\n",
    "        else:\n",
    "            current_chunk += chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "for chunk in chunker(python_example):\n",
    "    # print(chunk)\n",
    "    print(chunk.extract(python_example) + \"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "__len__() should return >= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m naive_chunker(python_example, \u001b[39m20\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39;49m(chunk))\n\u001b[1;32m      3\u001b[0m     \u001b[39m# print(chunk + \"\\n\\n\\n\")\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: __len__() should return >= 0"
     ]
    }
   ],
   "source": [
    "for chunk in naive_chunker(python_example, 20):\n",
    "    print(len(chunk))\n",
    "    # print(chunk + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7944cdd7aa821d7f8b2bb6dea516facfa4d1f3030f71d86c7f35d48e3ec6746"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
